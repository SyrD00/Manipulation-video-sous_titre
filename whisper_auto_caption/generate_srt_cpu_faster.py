"""
Exemple
ğŸ“ Progression:   0%|                                    | 2.88/1430.08 [01:49<15:07:45, 38.16s/sec]

1ï¸âƒ£ ğŸ“ Progression: 0%|

ğŸ‘‰ Câ€™est le titre de la barre (desc="ğŸ“ Progression") + lâ€™Ã©tat actuel.
Ici Ã§a dit : 0% de la vidÃ©o est transcrite.

2ï¸âƒ£ 2.88/1430.08

2.88 = nombre de secondes dâ€™audio dÃ©jÃ  transcrites.

1430.08 = durÃ©e totale de la vidÃ©o en secondes (â‰ˆ 23 min 50).

Donc tu as transcrit 2,88 secondes sur 1430 secondes â†’ dâ€™oÃ¹ le 0%.

3ï¸âƒ£ [01:49<15:07:45, 38.16s/sec]

Ã‡a ce sont les stats calculÃ©es par tqdm :

01:49 â†’ temps dÃ©jÃ  Ã©coulÃ© (1 min 49 s).

<15:07:45 â†’ estimation du temps restant (ici 15h ğŸ˜…, mais câ€™est faux car tu viens de commencer, tqdm 
extrapole mal au dÃ©but).

38.16s/sec â†’ vitesse estimÃ©e = combien de secondes dâ€™audio transcrites par seconde de calcul.

Ici : tu traites 38 secondes dâ€™audio en 1 seconde de CPU (câ€™est un ratio, pas du temps rÃ©el).

Comme au dÃ©but le modÃ¨le est lent Ã  charger, Ã§a paraÃ®t Ã©norme et faussÃ©. AprÃ¨s quelques minutes, Ã§a se 
stabilise.

ğŸš¨ Conclusion

Ton modÃ¨le large + CPU est en train de galÃ©rer :

23 minutes dâ€™audio Ã  38x temps rÃ©el = environ 15 heures de transcription ğŸ¤¯.

Câ€™est exactement ce que lâ€™ETA affiche (15:07:45).

"""
import argparse
import os
import time
from tqdm import tqdm
from faster_whisper import WhisperModel

def format_timestamp(seconds: float) -> str:
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = seconds % 60
    milliseconds = int((seconds - int(seconds)) * 1000)
    return f"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}"

def diagnostic_vitesse(speed: float) -> str:
    """Donne une recommandation selon la vitesse de traitement."""
    if speed < 1:
        return "ğŸŒ TrÃ¨s lent â†’ Conseil: utilisez un modÃ¨le plus petit (base/small) ou activez GPU si dispo."
    elif speed < 2:
        return "âš ï¸ Correct mais lent â†’ Conseil: vous pouvez rÃ©duire la taille du modÃ¨le ou fermer d'autres applis."
    elif speed < 5:
        return "âœ… Bon dÃ©bit â†’ Conseil: continuez comme Ã§a, le modÃ¨le choisi est adaptÃ©."
    else:
        return "ğŸš€ Excellent dÃ©bit â†’ Conseil: vous pouvez utiliser un modÃ¨le plus grand (ex: large) pour plus de prÃ©cision."

def transcribe_with_progress(audio_path: str, model_size="medium", language=None, task="transcribe"):
    print(f"ğŸš€ Chargement du modÃ¨le '{model_size}' optimisÃ© AVX2...")
    model = WhisperModel(model_size, device="cpu", compute_type="int8")
    print("âœ… ModÃ¨le chargÃ©.\n")

    print(f"ğŸ§ Transcription de : {audio_path}\n")
    start_time = time.time()

    segments_generator, info = model.transcribe(
        audio_path,
        language=language,
        task=task,
        beam_size=5,
    )
    if language is None:
        print(f"ğŸŒ Langue dÃ©tectÃ©e automatiquement : {info.language} (confiance {info.language_probability:.2f})")

    total_duration = info.duration
    srt_path = os.path.splitext(audio_path)[0] + ".srt"

    diagnostic_affiche = False  # variable pour afficher le diagnostic seulement 1 fois si lent

    with open(srt_path, "w", encoding="utf-8") as srt_file:
        progress_bar = tqdm(total=total_duration, desc="ğŸ“ Progression", unit="sec", ncols=100)
        current_time = 0.0

        for i, segment in enumerate(segments_generator):
            start = format_timestamp(segment.start)
            end = format_timestamp(segment.end)
            text = segment.text.strip()
            srt_file.write(f"{i+1}\n{start} --> {end}\n{text}\n\n")

            # Mise Ã  jour de la barre
            progress_bar.update(segment.end - current_time)
            current_time = segment.end

            # Calcul de vitesse
            elapsed = time.time() - start_time
            speed = current_time / elapsed if elapsed > 0 else 0

            # Afficher diagnostic **une seule fois si vitesse lente (<1x)**
            if not diagnostic_affiche and speed < 1:
                print(f"\nâš¡ Vitesse: {speed:.2f}x temps rÃ©el ({current_time/60:.1f} min audio en {elapsed/60:.1f} min rÃ©elles)")
                print("ğŸ’¡ " + diagnostic_vitesse(speed))
                diagnostic_affiche = True

        progress_bar.close()

    elapsed = time.time() - start_time
    print(f"\nâœ… Transcription terminÃ©e en {elapsed/60:.1f} minutes rÃ©elles")
    print(f"ğŸ“„ Fichier SRT gÃ©nÃ©rÃ© : {srt_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Transcrire un fichier audio en SRT avec Faster-Whisper (AVX2 optimisÃ©).")
    parser.add_argument("input_file", help="Chemin du fichier audio Ã  transcrire")
    parser.add_argument("--model_size", default="medium", help="Taille du modÃ¨le : tiny, base, small, medium, large")
    parser.add_argument("--language", default=None, help="Langue de l'audio, ex: ('auto', 'fr', 'en', ou 'ja'). Laisse vide pour auto-dÃ©tection")
    parser.add_argument("--task", default="transcribe", choices=["transcribe", "translate"], help="TÃ¢che : transcrire ou traduire")
    args = parser.parse_args()

    transcribe_with_progress(args.input_file, args.model_size, args.language, args.task)

