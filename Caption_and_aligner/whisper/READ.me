
"""
J'ai defini par defaut:
--model_size → par défaut "medium"

--language → par défaut "auto" (detection automatique de la langue)

--task → par défaut "transcribe"

Donc,pour juste lancer une transcription automatique avec le modèle medium
    python generate_srt_cpu.py mon_fichier.mp3


    Remarque:
    -Si t'as ffmpeg d'installé, le script peut lire directement les fichiers vidéo (mp4, mkv, mov, etc.) 
    et les fichiers audio (mp3, wav, m4a, etc.)
    -Le script génère un fichier SRT dans le même répertoire que le fichier d'entrée, avec le même nom 
    de base.
    -Faut toujours specifier le chemin complet du fichier audio/video si le script n'est pas dans le même
    répertoire que le fichier audio.

    NB:
    1) Si vous voulez un autre modèle, une autre langue ou une traduction,
    il suffit de préciser les arguments correspondants, par exemple: 
        a/modèle petit et rapide mais moins précis/plus lent et plus precis :
            python generate_srt_cpu.py mon_fichier.mp3 --model_size small
            python generate_srt_cpu.py mon_fichier.mp3 --model_size large 

        A retenir:
        tiny < base < small < medium < large
        Le modèle large est très lourd (2Go) et peut ne pas fonctionner sur certaines machines. 
        Le modèle medium est un bon compromis entre rapidité et précision. 
        Le modèle small est plus rapide mais moins précis. 
        Le modèle tiny est très rapide mais la précision est moindre.


        b/transcription en français si l'audio est en français :
            python generate_srt_cpu.py mon_fichier.mp3 --language fr

        NB : si vous êtes sûr de la langue, il est préférable de la spécifier pour améliorer la précision et la vitesse.
        Si vous ne spécifiez pas la langue, le modèle tentera de la détecter automatiquement. 

        c/traduction(exemple audio japonais vers sous-titres français):
            python generate_srt_cpu.py mon_fichier.mp3 --language ja --task translate
   
"""

"""pip install --upgrade pip
pip install --upgrade torch whisperx


 Installe WhisperX =pip install git+https://github.com/m-bain/whisperx.git ou pip install whisperx
pip install torchaudio
pip install librosa

ou en une commande pip install whisperx torchaudio librosa
pip install srt

pip install whisperx tqdm soundfile torch


"""



whisper marche pas pour le moment avec 3.13 


pip install git+https://github.com/openai/whisper.git
pip install git+https://github.com/SYSTRAN/faster-whisper.git

telecharger C++ 
ARM c’est pour processeurs ARM (Mac M1/M2, certains Windows sur ARM).

x86/x64 c’est pour les PC Windows classiques Intel/AMD.

Si tu es sur un PC Windows standard avec Intel ou AMD, il te faut la version x64 (64 bits) (et aussi x86 32 bits par précaution).

Télécharge les dernières versions x64 et x86 (les deux) pour Windows.
Même si tu as un PC 64 bits, parfois des libs 32 bits sont utilisées.
Pour juste faire fonctionner les DLL manquantes (comme onnxruntime), tu dois installer les Visual C++ Redistributables, pas les outils de compilation.

Donc, va sur ce lien-là (le bon) :

➡️ https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170

Là tu trouveras les fichiers à télécharger et installer, notamment :

x64 (64-bit)

x86 (32-bit)

Installe les deux, puis redémarre ton PC et réessaie.

